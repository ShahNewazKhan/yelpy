{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pprint\n",
    "import boto3\n",
    "import ujson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from AWS S3 buckets \n",
    "If you do not have access to the aida-practice-data bucket use the following public S3 bucket:\n",
    "[s3://dataincubator-course/mldata/yelp_train_academic_dataset_business.json.gz](s3://dataincubator-course/mldata/yelp_train_academic_dataset_business.json.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "skipping dir ['yelp', '']\n",
      "skipping dir ['yelp/business', '']\n",
      "skipping dir ['yelp/checkin', '']\n",
      "skipping dir ['yelp/photos', '']\n",
      "skipping dir ['yelp/reviews', '']\n",
      "skipping dir ['yelp/tip', '']\n",
      "skipping dir ['yelp/user', '']\n"
     ]
    }
   ],
   "source": [
    "# Create data dir\n",
    "!mkdir data\n",
    "\n",
    "# Instantiate s3 client\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = 'aida-practice-data'\n",
    "prefix = './data'\n",
    "\n",
    "# List all objects within a S3 bucket path\n",
    "response = s3_client.list_objects(Bucket = bucket)\n",
    "\n",
    "# Loop through each file\n",
    "for file in response['Contents']:\n",
    "\n",
    "    # Get the file name\n",
    "    name = file['Key'].rsplit('/', 1)\n",
    "    \n",
    "    if '.gz' not in name[1]:\n",
    "        print('skipping dir ' + str(name))\n",
    "        continue\n",
    "    \n",
    "    # Download each file to local disk\n",
    "    s3_client.download_file(bucket, file['Key'], prefix + '/' + name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate data in appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "drwxrwxr-x 8 shah shah 4096 Dec 30 01:30 .\r\n",
      "drwxrwxr-x 5 shah shah 4096 Dec 29 23:54 ..\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 business\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 checkin\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 photos\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 review\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 tip\r\n",
      "drwxrwxr-x 2 shah shah 4096 Dec 30 01:30 user\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/review && mv data/review.* data/review\n",
    "!mkdir data/business && mv data/business.* data/business\n",
    "!mkdir data/checkin && mv data/checkin.* data/checkin\n",
    "!mkdir data/photos && mv data/photos.* data/photos\n",
    "!mkdir data/tip && mv data/tip.* data/tip \n",
    "!mkdir data/user && mv data/user.* data/user\n",
    "\n",
    "!ls -la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the business data from the compressed json*.gz into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteratively ead in all the compressed business data into the file_content varia\n",
    "with gzip.open('data/business/business.json1.gz', 'rb') as f:\n",
    "    file_content = f.readlines() # reads each line as bytes and places in list\n",
    "with gzip.open('data/business/business.json2.gz', 'rb') as f:\n",
    "    file_content += f.readlines() # reads each line as bytes and places in list\n",
    "with gzip.open('data/business/business.json3.gz', 'rb') as f:\n",
    "    file_content += f.readlines() # reads each line as bytes and places in list\n",
    "with gzip.open('data/business/business.json4.gz', 'rb') as f:\n",
    "    file_content += f.readlines() # reads each line as bytes and places in list\n",
    "\n",
    "# Stringify each file_content list element to a str and strip \\n\n",
    "def cleanse_file_content_list():\n",
    "    for line in range(0, len(file_content)):\n",
    "        line_str = file_content[line].decode('utf-8')\n",
    "        file_content[line] = line_str.rstrip('\\n')\n",
    "        file_content[line] = ujson.loads(file_content[line])\n",
    "        \n",
    "cleanse_file_content_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file_contents into dataframe and normalize column 'city' strings to lowercase as well as drop empty values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business info dataframe prior to cleansing \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156639 entries, 0 to 156638\n",
      "Data columns (total 15 columns):\n",
      "address         156639 non-null object\n",
      "attributes      156639 non-null object\n",
      "business_id     156639 non-null object\n",
      "categories      156639 non-null object\n",
      "city            156639 non-null object\n",
      "hours           156639 non-null object\n",
      "is_open         156639 non-null int64\n",
      "latitude        156638 non-null float64\n",
      "longitude       156638 non-null float64\n",
      "name            156639 non-null object\n",
      "neighborhood    156639 non-null object\n",
      "postal_code     156639 non-null object\n",
      "review_count    156639 non-null int64\n",
      "stars           156639 non-null float64\n",
      "state           156639 non-null object\n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 17.9+ MB\n",
      "\n",
      "Business info dataframe after cleansing \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 156635 entries, 0 to 156638\n",
      "Data columns (total 15 columns):\n",
      "address         156635 non-null object\n",
      "attributes      156635 non-null object\n",
      "business_id     156635 non-null object\n",
      "categories      156635 non-null object\n",
      "city            156635 non-null object\n",
      "hours           156635 non-null object\n",
      "is_open         156635 non-null int64\n",
      "latitude        156635 non-null float64\n",
      "longitude       156635 non-null float64\n",
      "name            156635 non-null object\n",
      "neighborhood    156635 non-null object\n",
      "postal_code     156635 non-null object\n",
      "review_count    156635 non-null int64\n",
      "stars           156635 non-null float64\n",
      "state           156635 non-null object\n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create datafrom from file_contents\n",
    "df = pd.DataFrame(file_content)\n",
    "\n",
    "print('Business info dataframe prior to cleansing \\n')\n",
    "df.info()\n",
    "\n",
    "df['city'] = df['city'].str.lower()\n",
    "\n",
    "print('\\nBusiness info dataframe after cleansing \\n')\n",
    "# Remove & drop empty values\n",
    "df['city'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['city','latitude','longitude','stars'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the 'city' & 'stars' column to aggreate mean star venue rating by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City DF Summary: \n",
      "                stars\n",
      "count  156635.000000\n",
      "mean        3.647164\n",
      "std         0.977647\n",
      "min         1.000000\n",
      "25%         3.000000\n",
      "50%         3.500000\n",
      "75%         4.500000\n",
      "max         5.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>richmond heights</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charlotte</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toronto</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scottsdale</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phoenix</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city  stars\n",
       "0  richmond heights    2.0\n",
       "1         charlotte    4.5\n",
       "2           toronto    4.5\n",
       "3        scottsdale    3.0\n",
       "4           phoenix    4.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 'city' & 'stars' column to new dataframe\n",
    "city_df = df[['city', 'stars']]\n",
    "print('City DF Summary: \\n',city_df.describe())\n",
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>york</td>\n",
       "      <td>3.466292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>york regional municipality</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>youngtown</td>\n",
       "      <td>4.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>île des soeurs</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>île-des-soeurs</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           city     stars\n",
       "970                        york  3.466292\n",
       "971  york regional municipality  4.000000\n",
       "972                   youngtown  4.011628\n",
       "973              île des soeurs  4.000000\n",
       "974              île-des-soeurs  3.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby city and aggregate ratings\n",
    "grouped_city_df = city_df.groupby('city', as_index=False).agg({'stars': 'mean'})\n",
    "grouped_city_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1: City Model\n",
    "The venues belong to different cities.  You can image that the ratings in some\n",
    "cities are probably higher than others and use this as an estimator.\n",
    "\n",
    "Build an estimator that uses `groupby` and `mean` to compute the\n",
    "average rating in that city.  Use this as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add index for to grouped_city_df for lookup\n",
    "grouped_city_df.index = grouped_city_df['city']\n",
    "\n",
    "# Returns the mean of all venue ratings for the city passed in as 'record'\n",
    "def city_model(record):\n",
    "    return grouped_city_df['stars'][record]\n",
    "\n",
    "# Passing in the name of a city \n",
    "city_model('agincourt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question:** In the absence of any information about a city, what score would you assign a restaurant in that city?\n",
    "\n",
    "### **Answer:** The score assigned in this case would be an mean of all the means of all city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Lat Long Model\n",
    "You can imagine that a city-based model might not be sufficiently fine-grained.\n",
    "For example, we know that some neighborhoods are trendier than others.  We\n",
    "might consider a K Nearest Neighbors or Random Forest based on the latitude\n",
    "longitude as a way to understand neighborhood dynamics.\n",
    "\n",
    "You should implement a generic `ColumnSelectTransformer` that is passed which\n",
    "columns to select in the transformer and use a non-linear model like\n",
    "`sklearn.neighbors.KNeighborsRegressor` or\n",
    "`sklearn.ensemble.RandomForestRegressor` as the estimator (why would you choose\n",
    "a non-linear model?).  Bonus points if you wrap the estimator in\n",
    "`grid_search.GridSearchCV` and use cross-validation to determine the optimal\n",
    "value of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def __init__(self, columnList):\n",
    "#         # initialization code\n",
    "#         self.columnList = columnList\n",
    "        \n",
    "#     def fit(self, X, y=None):\n",
    "#         # fit the transformation\n",
    "        \n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return self.x # transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor Model RMSE:  0.5397648776574409\n",
      "KNeighborsRegressor Model RMSE:  0.5443068902216927\n",
      "KNeighborsRegressor Model RMSE:  0.5415582562477849\n",
      "KNeighborsRegressor Model RMSE:  0.5526223984840691\n",
      "KNeighborsRegressor Model RMSE:  0.5789077899450875\n"
     ]
    }
   ],
   "source": [
    "# # Label encode cities\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "fitted_le = le.fit(grouped_city_df['city'])\n",
    "df['le_city'] = le.transform(df['city'])\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array(df[['le_city','latitude','longitude']])\n",
    "y = np.array(df['stars'])\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    neigh_model = KNeighborsRegressor(n_neighbors=1)\n",
    "    neigh_model.fit(X, y)\n",
    "    \n",
    "    print('KNeighborsRegressor Model RMSE: ',sqrt(np.mean((neigh_model.predict(X_test) - y_test)**2)))\n",
    "\n",
    "knr_param_grid = {\n",
    "    \"n_neighbors\":[1,2,3,4,5],\n",
    "    \"weights\" : [\"uniform\",\"distance\"],\n",
    "    \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"p\" : [1,2],\n",
    "    \"metric\" : [\"euclidean\",\"manhattan\",\"chebyshev\",\"minkowski\",\"seuclidean\",\"mahalanobis\"]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    optimized_knr_model = KNeighborsRegressor()\n",
    "    knr_clf = GridSearchCV(optimized_knr_model, param_grid = knr_param_grid, n_jobs=3)\n",
    "    knr_clf.fit(X, y)\n",
    "    \n",
    "    print('OPTIMIZED KNeighborsRegressor Model RMSE: ', sqrt(np.mean((knr_clf.predict(X_test) - y_test)**2)))\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    rf_model = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    rf_model.fit(X, y)\n",
    "    \n",
    "    print('RandomForest Model RMSE: ',sqrt(np.mean((rf_model.predict(X_test) - y_test)**2)))\n",
    "\n",
    "# Use a full grid over all parameters\n",
    "rf_param_grid = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [1, 3],\n",
    "    \"min_samples_split\": [2, 3, 10],\n",
    "    \"min_samples_leaf\": [1, 3, 10],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    optimized_rf_model = RandomForestRegressor()\n",
    "    rf_clf = GridSearchCV(optimized_rf_model, param_grid = rf_param_grid, n_jobs=3)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    print('OPTIMIZED RandomForest Model RMSE: ', sqrt(np.mean((rf_clf.predict(X_test) - y_test)**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
